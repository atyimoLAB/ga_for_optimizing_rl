{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aba8f62-dc64-49c3-9caf-04d3a03d2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e470d040-60d0-4989-9298-4b122445721d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.20) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import jellyfish\n",
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import yaml\n",
    "import jellyfish\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04cbb3d8-2154-4870-8428-26e12f0f5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3486fbb8-9dd8-46b4-a694-7e31d0ed9581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1dfbf4-9531-4e01-98df-a3be0cd5ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option(\"display.max_columns\", 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14145681-e157-42d5-ae9c-dd0388367f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-unsafe_2.12-3.0.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.8/dist-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "org.elasticsearch#elasticsearch-spark-30_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-878f470d-1aad-48ba-9f3a-ce9a195dd570;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.elasticsearch#elasticsearch-spark-30_2.12;8.1.3 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.6 in central\n",
      "\tfound commons-logging#commons-logging;1.1.1 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.3.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound org.apache.spark#spark-yarn_2.12;3.2.0 in central\n",
      ":: resolution report :: resolve 279ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.1 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.3.1 from central in [default]\n",
      "\torg.apache.spark#spark-yarn_2.12;3.2.0 from central in [default]\n",
      "\torg.elasticsearch#elasticsearch-spark-30_2.12;8.1.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.8 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.6 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   7   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-878f470d-1aad-48ba-9f3a-ce9a195dd570\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/5ms)\n",
      "26/02/02 20:36:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/02 20:37:00 WARN SparkContext: Please ensure that the number of slots available on your executors is limited by the number of cores to task cpus and not another custom resource. If cores is not the limiting resource then dynamic allocation will not work properly!\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"assigning_labels\") \\\n",
    "    .master(\"spark://barravento:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.elasticsearch:elasticsearch-spark-30_2.12:8.1.3\") \\\n",
    "    .config(\"spark.es.nodes\", \"barravento\") \\\n",
    "    .config(\"spark.es.port\", \"9200\") \\\n",
    "    .config(\"spark.es.nodes.wan.only\", \"false\") \\\n",
    "    .config(\"spark.es.resource\", \"dbb2\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 16) \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"256m\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "# just to ensure that \n",
    "sc.setCheckpointDir(\"hdfs://barravento:9000/spark-checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b89b03-edcd-41b7-bad9-fd35c5174c76",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "419e0e39-7a73-4b94-9f4c-355107d43dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_side_by_side(\n",
    "    df,\n",
    "    cfg,\n",
    "    extras_front=None,\n",
    "    extras_back=None,\n",
    "    strict=False,\n",
    "    field_order=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Reordena colunas para comparação A vs B com base em cfg['dataset'], mantendo nomes originais.\n",
    "\n",
    "    Retorna: df.select(...) com colunas em ordem:\n",
    "      extras_front\n",
    "      left_id, right_id (se existirem)\n",
    "      [left_field, right_field] para cada campo lógico em cfg['dataset']['fields']\n",
    "      extras_back\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    strict: se True, levanta erro quando alguma coluna esperada não existe no df.\n",
    "            se False, cria coluna NULL com o nome esperado.\n",
    "    field_order: lista opcional com a ordem dos campos lógicos (ex.: [\"nome\",\"nome_mae\",\"dt_nasc\",\"sexo\"]).\n",
    "                 se None, usa a ordem do cfg['dataset']['fields'].\n",
    "    \"\"\"\n",
    "    ds = cfg[\"dataset\"]\n",
    "    left_id  = ds[\"keys\"][\"left_id\"]\n",
    "    right_id = ds[\"keys\"][\"right_id\"]\n",
    "    fields   = ds[\"fields\"]  # dict: logical_field -> {left, right, sim, weight, penalty}\n",
    "\n",
    "    extras_front = extras_front or []\n",
    "    extras_back  = extras_back or []\n",
    "\n",
    "    existing = set(df.columns)\n",
    "\n",
    "    # Mantém só extras que existem\n",
    "    extras_front = [c for c in extras_front if c in existing]\n",
    "    extras_back  = [c for c in extras_back if c in existing]\n",
    "\n",
    "    # Define ordem dos campos lógicos\n",
    "    logical_fields = field_order if field_order is not None else list(fields.keys())\n",
    "\n",
    "    def col_or_null(colname: str):\n",
    "        if colname in existing:\n",
    "            return F.col(colname)\n",
    "        if strict:\n",
    "            raise ValueError(f\"Coluna ausente no DataFrame: '{colname}'\")\n",
    "        return F.lit(None).alias(colname)\n",
    "\n",
    "    cols = []\n",
    "\n",
    "    # 1) extras_front\n",
    "    cols += [F.col(c) for c in extras_front]\n",
    "\n",
    "    # 2) ids\n",
    "    cols.append(col_or_null(left_id))\n",
    "    cols.append(col_or_null(right_id))\n",
    "\n",
    "    # 3) pares lado a lado (mantendo nomes originais do YAML: left/right)\n",
    "    for lf in logical_fields:\n",
    "        spec = fields[lf]\n",
    "        lcol = spec[\"left\"]\n",
    "        rcol = spec[\"right\"]\n",
    "        cols.append(col_or_null(lcol))\n",
    "        cols.append(col_or_null(rcol))\n",
    "\n",
    "    # 4) extras_back\n",
    "    cols += [F.col(c) for c in extras_back]\n",
    "\n",
    "    return df.select(*cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff97aa4-248d-434a-a668-327e1d47f2d9",
   "metadata": {},
   "source": [
    "# Lendo bases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ca97f-1c9a-4607-a5ca-723f481210ee",
   "metadata": {},
   "source": [
    "## Lendo arquivo de configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09d6378c-8792-4ece-9130-d0d13a41dec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': 1,\n",
       " 'dataset': {'keys': {'left_id': 'id_cidacs_a', 'right_id': 'id_cidacs_b'},\n",
       "  'label': 'match_status',\n",
       "  'fields': {'nome': {'left': 'nome_a',\n",
       "    'right': 'nome_b',\n",
       "    'sim': 'jaro_winkler',\n",
       "    'weight': 1,\n",
       "    'penalty': 0.1},\n",
       "   'nome_mae': {'left': 'nome_mae_a',\n",
       "    'right': 'nome_mae_b',\n",
       "    'sim': 'jaro_winkler',\n",
       "    'weight': 1,\n",
       "    'penalty': 0.1},\n",
       "   'dt_nasc': {'left': 'dt_nasc_a',\n",
       "    'right': 'dt_nasc_b',\n",
       "    'sim': 'hamming',\n",
       "    'weight': 1,\n",
       "    'penalty': 0.1},\n",
       "   'sexo': {'left': 'sexo_a',\n",
       "    'right': 'sexo_b',\n",
       "    'sim': 'overlap',\n",
       "    'weight': 1,\n",
       "    'penalty': 0.1}}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_PATH = \"config_traindata.yaml\"\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c5801-bd48-4c74-b416-5537ad630be8",
   "metadata": {},
   "source": [
    "## Lendo base construida para a revisão manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1bd744f-544c-4b59-aad4-0b5c39b79e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "      <th>target_pos</th>\n",
       "      <th>es_candidates</th>\n",
       "      <th>es_candidate</th>\n",
       "      <th>es_candidate_id</th>\n",
       "      <th>es_candidate_score</th>\n",
       "      <th>id_cidacs_a</th>\n",
       "      <th>nome_a</th>\n",
       "      <th>nome_mae_a</th>\n",
       "      <th>dt_nasc_a</th>\n",
       "      <th>sexo_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1059</td>\n",
       "      <td>CRISTIANE SILVA DOS SANTOS</td>\n",
       "      <td>CRISTIANE SILVA DOS SANTOS</td>\n",
       "      <td>20071212</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[(1059, 32.776756, {}), (778174, 25.224531, {}...</td>\n",
       "      <td>(1059, 32.776756, {})</td>\n",
       "      <td>1059</td>\n",
       "      <td>32.776756</td>\n",
       "      <td>1059</td>\n",
       "      <td>GABRIEL VASCONCELOS SANTOS</td>\n",
       "      <td>CRISTIANE SILVA DOS SANTOS</td>\n",
       "      <td>20071212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>493476</td>\n",
       "      <td>ARIELA LUIZA DA</td>\n",
       "      <td>ANA DANIELE LIMA DOS</td>\n",
       "      <td>20080719</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[(493476, 73.399155, {}), (416052, 48.723595, ...</td>\n",
       "      <td>(493476, 73.399155, {})</td>\n",
       "      <td>493476</td>\n",
       "      <td>73.399155</td>\n",
       "      <td>493476</td>\n",
       "      <td>ARIELA LUIZA DA SILVA</td>\n",
       "      <td>ANA DANIELE LIMA DOS SANTOS</td>\n",
       "      <td>20080719</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                      nome_b                  nome_mae_b  \\\n",
       "0        1059  CRISTIANE SILVA DOS SANTOS  CRISTIANE SILVA DOS SANTOS   \n",
       "1      493476             ARIELA LUIZA DA        ANA DANIELE LIMA DOS   \n",
       "\n",
       "  dt_nasc_b sexo_b  target_pos  \\\n",
       "0  20071212      1           1   \n",
       "1  20080719      1           1   \n",
       "\n",
       "                                       es_candidates             es_candidate  \\\n",
       "0  [(1059, 32.776756, {}), (778174, 25.224531, {}...    (1059, 32.776756, {})   \n",
       "1  [(493476, 73.399155, {}), (416052, 48.723595, ...  (493476, 73.399155, {})   \n",
       "\n",
       "  es_candidate_id  es_candidate_score id_cidacs_a                      nome_a  \\\n",
       "0            1059           32.776756        1059  GABRIEL VASCONCELOS SANTOS   \n",
       "1          493476           73.399155      493476       ARIELA LUIZA DA SILVA   \n",
       "\n",
       "                    nome_mae_a dt_nasc_a sexo_a  \n",
       "0   CRISTIANE SILVA DOS SANTOS  20071212      1  \n",
       "1  ANA DANIELE LIMA DOS SANTOS  20080719      2  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_df = spark.read.parquet('hdfs://barravento:9000/data/df_for_manual_review.parquet')\n",
    "link_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d66420b8-9098-4ff4-abc0-bd9c15d27402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_a</th>\n",
       "      <th>nome_a</th>\n",
       "      <th>nome_mae_a</th>\n",
       "      <th>dt_nasc_a</th>\n",
       "      <th>sexo_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>YASMIM VITORIA MATIAS FONSECA</td>\n",
       "      <td>TACIANY DOS SANTOS</td>\n",
       "      <td>20071122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PEDRO HENRIQUE MARTINS DE CARVALHO</td>\n",
       "      <td>FRANCILEIDE DOS SANTOS ALVES</td>\n",
       "      <td>20061102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_a                              nome_a  \\\n",
       "0           1       YASMIM VITORIA MATIAS FONSECA   \n",
       "1           2  PEDRO HENRIQUE MARTINS DE CARVALHO   \n",
       "\n",
       "                     nome_mae_a dt_nasc_a sexo_a  \n",
       "0            TACIANY DOS SANTOS  20071122      2  \n",
       "1  FRANCILEIDE DOS SANTOS ALVES  20061102      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_a = spark.read.parquet('hdfs://barravento:9000/data/synthetic-dataset-A.parquet')\n",
    "base_a.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9235efaa-3619-4f9a-9aec-8411be710eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>788</td>\n",
       "      <td>RUAN CESAR COSTA DE JESUS</td>\n",
       "      <td>JUSSARA CAROLINA R ALBUQUERQUE</td>\n",
       "      <td>20080531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1261</td>\n",
       "      <td>YASMIN MUNIZ MARCELINO</td>\n",
       "      <td>VERA LUCIA RIBEIRO</td>\n",
       "      <td>20080516</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_cidacs_b                     nome_b                      nome_mae_b  \\\n",
       "0         788  RUAN CESAR COSTA DE JESUS  JUSSARA CAROLINA R ALBUQUERQUE   \n",
       "1        1261     YASMIN MUNIZ MARCELINO              VERA LUCIA RIBEIRO   \n",
       "\n",
       "  dt_nasc_b sexo_b  \n",
       "0  20080531      1  \n",
       "1  20080516      2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_b = spark.read.parquet('hdfs://barravento:9000/data/synthetic-datasets-b-1000.parquet')\n",
    "base_b.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d0fd3-0915-46d9-aaf8-68b94f2fde72",
   "metadata": {},
   "source": [
    "# Organizando base para revisão manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d9af559-e1c8-4231-967f-9b83a6610743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_pos</th>\n",
       "      <th>es_candidate_score</th>\n",
       "      <th>es_candidate_id</th>\n",
       "      <th>id_cidacs_a</th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_a</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_a</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_a</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_a</th>\n",
       "      <th>sexo_b</th>\n",
       "      <th>es_candidates</th>\n",
       "      <th>es_candidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32.776756</td>\n",
       "      <td>1059</td>\n",
       "      <td>1059</td>\n",
       "      <td>1059</td>\n",
       "      <td>GABRIEL VASCONCELOS SANTOS</td>\n",
       "      <td>CRISTIANE SILVA DOS SANTOS</td>\n",
       "      <td>CRISTIANE SILVA DOS SANTOS</td>\n",
       "      <td>CRISTIANE SILVA DOS SANTOS</td>\n",
       "      <td>20071212</td>\n",
       "      <td>20071212</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[(1059, 32.776756, {}), (778174, 25.224531, {}...</td>\n",
       "      <td>(1059, 32.776756, {})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>73.399155</td>\n",
       "      <td>493476</td>\n",
       "      <td>493476</td>\n",
       "      <td>493476</td>\n",
       "      <td>ARIELA LUIZA DA SILVA</td>\n",
       "      <td>ARIELA LUIZA DA</td>\n",
       "      <td>ANA DANIELE LIMA DOS SANTOS</td>\n",
       "      <td>ANA DANIELE LIMA DOS</td>\n",
       "      <td>20080719</td>\n",
       "      <td>20080719</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[(493476, 73.399155, {}), (416052, 48.723595, ...</td>\n",
       "      <td>(493476, 73.399155, {})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>80.128960</td>\n",
       "      <td>364678</td>\n",
       "      <td>364678</td>\n",
       "      <td>364678</td>\n",
       "      <td>JENIFER VITORIA DA SILVA SANTOS</td>\n",
       "      <td>JENIFER VITORIA DA SILVA SANTOS</td>\n",
       "      <td>DANIELE OLIVEIRA SILVA</td>\n",
       "      <td>DANIELE OLIVEIRA SILVA</td>\n",
       "      <td>20061018</td>\n",
       "      <td>20061018</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[(364678, 80.12896, {}), (567916, 40.68721, {}...</td>\n",
       "      <td>(364678, 80.12896, {})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>58.016700</td>\n",
       "      <td>851014</td>\n",
       "      <td>851014</td>\n",
       "      <td>996184</td>\n",
       "      <td>ARTHUR GABRIEL ABREU BARROS</td>\n",
       "      <td>ARTHUR GABRIEL ABREU BARROS</td>\n",
       "      <td>ADRIANA CAETANO SANTOS NUNES</td>\n",
       "      <td>MAIRA VANESSA SANTOS</td>\n",
       "      <td>20100616</td>\n",
       "      <td>20090604</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[(996184, 89.75126, {}), (812302, 58.0167, {})...</td>\n",
       "      <td>(851014, 58.0167, {})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>71.861850</td>\n",
       "      <td>750623</td>\n",
       "      <td>750623</td>\n",
       "      <td>750623</td>\n",
       "      <td>ATHANY CORREA DE CARVALHO</td>\n",
       "      <td>ATHANY CORREA DE</td>\n",
       "      <td>FABIANA SILVA DE ASSIS</td>\n",
       "      <td>FABIANA SILVA DE</td>\n",
       "      <td>20090725</td>\n",
       "      <td>20090725</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[(750623, 71.86185, {}), (779657, 42.328606, {...</td>\n",
       "      <td>(750623, 71.86185, {})</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_pos  es_candidate_score es_candidate_id id_cidacs_a id_cidacs_b  \\\n",
       "0           1           32.776756            1059        1059        1059   \n",
       "1           1           73.399155          493476      493476      493476   \n",
       "2           1           80.128960          364678      364678      364678   \n",
       "3           3           58.016700          851014      851014      996184   \n",
       "4           1           71.861850          750623      750623      750623   \n",
       "\n",
       "                            nome_a                           nome_b  \\\n",
       "0       GABRIEL VASCONCELOS SANTOS       CRISTIANE SILVA DOS SANTOS   \n",
       "1            ARIELA LUIZA DA SILVA                  ARIELA LUIZA DA   \n",
       "2  JENIFER VITORIA DA SILVA SANTOS  JENIFER VITORIA DA SILVA SANTOS   \n",
       "3      ARTHUR GABRIEL ABREU BARROS      ARTHUR GABRIEL ABREU BARROS   \n",
       "4        ATHANY CORREA DE CARVALHO                 ATHANY CORREA DE   \n",
       "\n",
       "                     nome_mae_a                  nome_mae_b dt_nasc_a  \\\n",
       "0    CRISTIANE SILVA DOS SANTOS  CRISTIANE SILVA DOS SANTOS  20071212   \n",
       "1   ANA DANIELE LIMA DOS SANTOS        ANA DANIELE LIMA DOS  20080719   \n",
       "2        DANIELE OLIVEIRA SILVA      DANIELE OLIVEIRA SILVA  20061018   \n",
       "3  ADRIANA CAETANO SANTOS NUNES        MAIRA VANESSA SANTOS  20100616   \n",
       "4        FABIANA SILVA DE ASSIS            FABIANA SILVA DE  20090725   \n",
       "\n",
       "  dt_nasc_b sexo_a sexo_b                                      es_candidates  \\\n",
       "0  20071212      1      1  [(1059, 32.776756, {}), (778174, 25.224531, {}...   \n",
       "1  20080719      2      1  [(493476, 73.399155, {}), (416052, 48.723595, ...   \n",
       "2  20061018      2      2  [(364678, 80.12896, {}), (567916, 40.68721, {}...   \n",
       "3  20090604      2      2  [(996184, 89.75126, {}), (812302, 58.0167, {})...   \n",
       "4  20090725      2      1  [(750623, 71.86185, {}), (779657, 42.328606, {...   \n",
       "\n",
       "              es_candidate  \n",
       "0    (1059, 32.776756, {})  \n",
       "1  (493476, 73.399155, {})  \n",
       "2   (364678, 80.12896, {})  \n",
       "3    (851014, 58.0167, {})  \n",
       "4   (750623, 71.86185, {})  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_df = select_side_by_side(\n",
    "    link_df,\n",
    "    cfg,\n",
    "    extras_front=[\"target_pos\", \"es_candidate_score\", \"es_candidate_id\"],\n",
    "    extras_back=[\"es_candidates\", \"es_candidate\"],\n",
    "    strict=False\n",
    ")\n",
    "\n",
    "link_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f082d7e8-98ed-4888-83f8-e20f4cb9dfd5",
   "metadata": {},
   "source": [
    "# Atribuindo rótulo em \"match_status\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed84381f-a676-4d6d-a963-e469653722b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|match_status|count|\n",
      "+------------+-----+\n",
      "|           1|  560|\n",
      "|           0|  440|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "link_df = link_df.withColumn('match_status', F.when(F.col('id_cidacs_a') == F.col('id_cidacs_b'), 1).otherwise(F.lit(0)))\n",
    "link_df.select(\"match_status\").groupBy(\"match_status\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7642ea-e85c-4a18-9450-2396554e8ebe",
   "metadata": {},
   "source": [
    "## Escrevendo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d17499c2-1560-4b59-8775-9e684a77f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "link_df.write.parquet(\"hdfs://barravento:9000/data/result/train_dataset_raw.parquet\", mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
