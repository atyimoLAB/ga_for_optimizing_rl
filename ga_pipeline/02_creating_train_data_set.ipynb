{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e470d040-60d0-4989-9298-4b122445721d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.20) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import jellyfish\n",
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import yaml\n",
    "import jellyfish\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aba8f62-dc64-49c3-9caf-04d3a03d2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04cbb3d8-2154-4870-8428-26e12f0f5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3486fbb8-9dd8-46b4-a694-7e31d0ed9581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c1dfbf4-9531-4e01-98df-a3be0cd5ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option(\"display.max_columns\", 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ca1fe1-534e-4c5a-855f-4a111e243877",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14145681-e157-42d5-ae9c-dd0388367f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.8/dist-packages/pyspark/jars/spark-unsafe_2.12-3.0.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.8/dist-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "org.elasticsearch#elasticsearch-spark-30_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-38cf9473-4c75-443d-b36a-9287fb2e57c9;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.elasticsearch#elasticsearch-spark-30_2.12;8.1.3 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.6 in central\n",
      "\tfound commons-logging#commons-logging;1.1.1 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.3.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound org.apache.spark#spark-yarn_2.12;3.2.0 in central\n",
      ":: resolution report :: resolve 320ms :: artifacts dl 2ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.1 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.3.1 from central in [default]\n",
      "\torg.apache.spark#spark-yarn_2.12;3.2.0 from central in [default]\n",
      "\torg.elasticsearch#elasticsearch-spark-30_2.12;8.1.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.8 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.6 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   7   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-38cf9473-4c75-443d-b36a-9287fb2e57c9\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/5ms)\n",
      "26/02/02 21:13:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/02 21:13:34 WARN SparkContext: Please ensure that the number of slots available on your executors is limited by the number of cores to task cpus and not another custom resource. If cores is not the limiting resource then dynamic allocation will not work properly!\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TrainDataSet\") \\\n",
    "    .master(\"spark://barravento:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.elasticsearch:elasticsearch-spark-30_2.12:8.1.3\") \\\n",
    "    .config(\"spark.es.nodes\", \"barravento\") \\\n",
    "    .config(\"spark.es.port\", \"9200\") \\\n",
    "    .config(\"spark.es.nodes.wan.only\", \"false\") \\\n",
    "    .config(\"spark.es.resource\", \"dbb2\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 16) \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"256m\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "# just to ensure that \n",
    "sc.setCheckpointDir(\"hdfs://barravento:9000/spark-checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95cd8a2-4d56-419e-b893-3fe06b7b75ed",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01914036-3c71-4109-be19-1601f160a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaro_winkler(col1, col2, weight, penality):\n",
    "    if (col1 == \"\") or (col2 == \"\") or (col1 == None) or (col2 == None):\n",
    "        return penality\n",
    "    else:\n",
    "        return jellyfish.jaro_winkler_similarity(str(col1), str(col2)) * weight\n",
    "udf_jaro_winkler = F.udf(jaro_winkler, DoubleType())\n",
    "\n",
    "def hamming(col1, col2, weight, penality):\n",
    "    if (col1 == \"\") or (col2 == \"\") or (col1 == None) or (col2 == None):\n",
    "        return penality\n",
    "    else: \n",
    "        max_size = max(len(col1), len(col2))\n",
    "        return (1.0 - float(jellyfish.hamming_distance(str(col1), str(col2)) / max_size)) * weight\n",
    "udf_hamming = F.udf(hamming, DoubleType())\n",
    "\n",
    "\n",
    "def overlap(col1, col2, weight, penality):\n",
    "    if (col1 == \"\") or (col2 == \"\") or (col1 == None) or (col2 == None) or (col1 != col2):\n",
    "        return penality\n",
    "    else: \n",
    "        return 1.0 * weight\n",
    "udf_overlap = F.udf(overlap, DoubleType())\n",
    "\n",
    "def sim_hub(col1, col2, sim_type, weight, penality):\n",
    "    if sim_type == \"jaro_winkler\":\n",
    "        return jaro_winkler(str(col1), str(col2), weight, penality)\n",
    "    elif sim_type == \"hamming\":\n",
    "        return hamming(str(col1), str(col2), weight, penality)\n",
    "    else: \n",
    "        return overlap(str(col1), str(col2), weight, penality)\n",
    "udf_sim_hub = F.udf(sim_hub, DoubleType())\n",
    "\n",
    "def calcula_similaridades(df, config, params):\n",
    "    config_ = config['dataset']['fields']\n",
    "    for pair in config['dataset']['fields']:\n",
    "        weight = params[f\"w_{pair}\"]\n",
    "        penalty = params[f\"p_{pair}\"]\n",
    "        right_var = config_[pair]['right']\n",
    "        left_var = config_[pair]['left']\n",
    "        similarity = config_[pair]['sim']\n",
    "        \n",
    "        df = df.withColumn(f\"sim_{right_var}_{left_var}\", udf_sim_hub(F.col(right_var), \n",
    "                                                                      F.col(left_var), \n",
    "                                                                      F.lit(similarity), \n",
    "                                                                      F.lit(weight), \n",
    "                                                                      F.lit(penalty)))\\\n",
    "               .withColumn(f\"w_{pair}\", F.lit(params[f\"w_{pair}\"]))\\\n",
    "               .withColumn(f\"p_{pair}\", F.lit(params[f\"p_{pair}\"]))\n",
    "    return df\n",
    "\n",
    "def calcula_similaridade(df, config, params):\n",
    "    config_ = config['dataset']['fields']\n",
    "    score_max = 0\n",
    "    for pair in config['dataset']['fields']:\n",
    "        score_max += params[f\"w_{pair}\"]\n",
    "        \n",
    "    # score_max = sum([float(cfg['dataset']['fields'][x]['weight']) for x in cfg['dataset']['fields'].keys()])\n",
    "    \n",
    "    vars_ = []\n",
    "    for pair in config['dataset']['fields']:\n",
    "        right_var = config_[pair]['right']\n",
    "        left_var = config_[pair]['left']\n",
    "\n",
    "        vars_.append(f\"sim_{right_var}_{left_var}\")\n",
    "    \n",
    "    return df.withColumn(\"total_score\", F.lit(sum(F.col(c) for c in vars_))/F.lit(score_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff97aa4-248d-434a-a668-327e1d47f2d9",
   "metadata": {},
   "source": [
    "# Lendo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1bd744f-544c-4b59-aad4-0b5c39b79e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_pos</th>\n",
       "      <th>es_candidate_score</th>\n",
       "      <th>es_candidate_id</th>\n",
       "      <th>id_cidacs_a</th>\n",
       "      <th>id_cidacs_b</th>\n",
       "      <th>nome_a</th>\n",
       "      <th>nome_b</th>\n",
       "      <th>nome_mae_a</th>\n",
       "      <th>nome_mae_b</th>\n",
       "      <th>dt_nasc_a</th>\n",
       "      <th>dt_nasc_b</th>\n",
       "      <th>sexo_a</th>\n",
       "      <th>sexo_b</th>\n",
       "      <th>es_candidates</th>\n",
       "      <th>es_candidate</th>\n",
       "      <th>match_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>49.92177</td>\n",
       "      <td>84146</td>\n",
       "      <td>84146</td>\n",
       "      <td>509978</td>\n",
       "      <td>MARIA VITORIA PESSOA BARBOSA</td>\n",
       "      <td>MARIA VITORIA PESSOA BARBOSA</td>\n",
       "      <td>JAMILE DE OLIVEIRA SILVA</td>\n",
       "      <td>GIZELLE DE OLIVEIRA LIMA</td>\n",
       "      <td>20090212</td>\n",
       "      <td>20080203</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[(509978, 93.56702, {}), (819674, 49.92177, {}...</td>\n",
       "      <td>(84146, 49.92177, {})</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>92.05257</td>\n",
       "      <td>124538</td>\n",
       "      <td>124538</td>\n",
       "      <td>124538</td>\n",
       "      <td>WELLINGTON EDGAR ALVES SANTOS</td>\n",
       "      <td>WELLINGTON EDGAR ALVES</td>\n",
       "      <td>SORAIA ARAUJO NOGUEIRA</td>\n",
       "      <td>SORAIA ARAUJO</td>\n",
       "      <td>20100710</td>\n",
       "      <td>20100710</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[(124538, 92.05257, {}), (831032, 57.37523, {}...</td>\n",
       "      <td>(124538, 92.05257, {})</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_pos  es_candidate_score es_candidate_id id_cidacs_a id_cidacs_b  \\\n",
       "0           3            49.92177           84146       84146      509978   \n",
       "1           1            92.05257          124538      124538      124538   \n",
       "\n",
       "                          nome_a                        nome_b  \\\n",
       "0   MARIA VITORIA PESSOA BARBOSA  MARIA VITORIA PESSOA BARBOSA   \n",
       "1  WELLINGTON EDGAR ALVES SANTOS        WELLINGTON EDGAR ALVES   \n",
       "\n",
       "                 nome_mae_a                nome_mae_b dt_nasc_a dt_nasc_b  \\\n",
       "0  JAMILE DE OLIVEIRA SILVA  GIZELLE DE OLIVEIRA LIMA  20090212  20080203   \n",
       "1    SORAIA ARAUJO NOGUEIRA             SORAIA ARAUJO  20100710  20100710   \n",
       "\n",
       "  sexo_a sexo_b                                      es_candidates  \\\n",
       "0      2      2  [(509978, 93.56702, {}), (819674, 49.92177, {}...   \n",
       "1      1      2  [(124538, 92.05257, {}), (831032, 57.37523, {}...   \n",
       "\n",
       "             es_candidate  match_status  \n",
       "0   (84146, 49.92177, {})             0  \n",
       "1  (124538, 92.05257, {})             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_df = spark.read.parquet(\"hdfs://barravento:9000/data/result/train_dataset_raw.parquet\").repartition(128)\n",
    "link_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20d4446-5200-4cf2-93c4-22856df5b143",
   "metadata": {},
   "source": [
    "# Calculando similaridades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1551129b-c6d2-4a2e-a2c4-2e914062086c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': 1,\n",
       " 'dataset': {'keys': {'left_id': 'id_cidacs_a', 'right_id': 'id_cidacs_b'},\n",
       "  'label': 'match_status',\n",
       "  'fields': {'nome': {'left': 'nome_a',\n",
       "    'right': 'nome_b',\n",
       "    'sim': 'jaro_winkler',\n",
       "    'weight': {'low': 0.0, 'high': 6.0, 'step': 0.05},\n",
       "    'penalty': {'low': 0.0, 'high': 1.0, 'step': 0.01}},\n",
       "   'nome_mae': {'left': 'nome_mae_a',\n",
       "    'right': 'nome_mae_b',\n",
       "    'sim': 'jaro_winkler',\n",
       "    'weight': {'low': 0.0, 'high': 6.0, 'step': 0.05},\n",
       "    'penalty': {'low': 0.0, 'high': 1.0, 'step': 0.01}},\n",
       "   'dt_nasc': {'left': 'dt_nasc_a',\n",
       "    'right': 'dt_nasc_b',\n",
       "    'sim': 'hamming',\n",
       "    'weight': {'low': 0.0, 'high': 6.0, 'step': 0.05},\n",
       "    'penalty': {'low': 0.0, 'high': 1.0, 'step': 0.01}},\n",
       "   'sexo': {'left': 'sexo_a',\n",
       "    'right': 'sexo_b',\n",
       "    'sim': 'overlap',\n",
       "    'weight': {'low': 0.0, 'high': 6.0, 'step': 0.05},\n",
       "    'penalty': {'low': 0.0, 'high': 1.0, 'step': 0.01}}}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_PATH = \"config_traindata_all.yaml\"\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec4e737-d906-462c-ba46-6b1ea8173b24",
   "metadata": {},
   "source": [
    "# Criando grade de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1b8e435-badd-47da-892e-fd50bd348df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from itertools import product\n",
    "\n",
    "# def arange_inclusive(low, high, step):\n",
    "#     # evita drift de float\n",
    "#     n = int(round((high - low) / step)) + 1\n",
    "#     return [round(low + i * step, 10) for i in range(n)]\n",
    "\n",
    "# def iter_all_param_sets(cfg):\n",
    "#     fields = cfg[\"dataset\"][\"fields\"]  # dict: nome, nome_mae, dt_nasc, sexo...\n",
    "\n",
    "#     # constrói grid por campo\n",
    "#     grids = {}\n",
    "#     for key, spec in fields.items():\n",
    "#         w = spec[\"weight\"]\n",
    "#         p = spec[\"penalty\"]\n",
    "#         w_vals = arange_inclusive(w[\"low\"], w[\"high\"], w[\"step\"])\n",
    "#         p_vals = arange_inclusive(p[\"low\"], p[\"high\"], p[\"step\"])\n",
    "#         grids[key] = list(product(w_vals, p_vals))  # (w, p)\n",
    "\n",
    "#     field_keys = list(fields.keys())\n",
    "\n",
    "#     # produto cartesiano entre os campos\n",
    "#     for combo in product(*(grids[k] for k in field_keys)):\n",
    "#         # combo é uma tupla: [(w_nome,p_nome), (w_nome_mae,p_nome_mae), ...]\n",
    "#         out = {}\n",
    "#         for k, (w, p) in zip(field_keys, combo):\n",
    "#             out[f\"w_{k}\"] = w\n",
    "#             out[f\"p_{k}\"] = p\n",
    "#         yield out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb07460-c593-4bd1-ad14-e898e3b68120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_param_sets(cfg, n, seed=2026):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    fields = cfg[\"dataset\"][\"fields\"]\n",
    "    field_keys = list(fields.keys())\n",
    "\n",
    "    # prepara valores por campo\n",
    "    w_vals_by = {}\n",
    "    p_vals_by = {}\n",
    "    for k in field_keys:\n",
    "        w = fields[k][\"weight\"]\n",
    "        p = fields[k][\"penalty\"]\n",
    "        w_vals_by[k] = np.round(np.arange(w[\"low\"], w[\"high\"] + 1e-9, w[\"step\"]), 10)\n",
    "        p_vals_by[k] = np.round(np.arange(p[\"low\"], p[\"high\"] + 1e-9, p[\"step\"]), 10)\n",
    "\n",
    "    # amostra\n",
    "    rows = []\n",
    "    for _ in range(n):\n",
    "        row = {}\n",
    "        for k in field_keys:\n",
    "            row[f\"w_{k}\"] = float(rng.choice(w_vals_by[k]))\n",
    "            row[f\"p_{k}\"] = float(rng.choice(p_vals_by[k]))\n",
    "        rows.append(row)\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7faeafa5-481b-44c0-b56f-200fe405155f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'w_nome': 5.15,\n",
       "  'p_nome': 0.18,\n",
       "  'w_nome_mae': 0.15,\n",
       "  'p_nome_mae': 0.64,\n",
       "  'w_dt_nasc': 2.2,\n",
       "  'p_dt_nasc': 0.47,\n",
       "  'w_sexo': 0.45,\n",
       "  'p_sexo': 0.37},\n",
       " {'w_nome': 3.85,\n",
       "  'p_nome': 0.35,\n",
       "  'w_nome_mae': 5.0,\n",
       "  'p_nome_mae': 0.79,\n",
       "  'w_dt_nasc': 4.25,\n",
       "  'p_dt_nasc': 0.91,\n",
       "  'w_sexo': 4.35,\n",
       "  'p_sexo': 0.17}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = sample_param_sets(cfg, n=50, seed=2026)\n",
    "rows[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70ffd969-5484-48f2-b2f0-9cc60b61311d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62d4c5e1-3586-4696-9d2b-0da8970c0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = iter_all_param_sets(cfg)\n",
    "# for _ in range(5):\n",
    "#     print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95fffa52-08e2-4282-bf71-d5dce90b05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d94000-db2c-4391-8b2b-82b43cd7161f",
   "metadata": {},
   "source": [
    "# Criando as linhas da base de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71e60b1c-a3ba-4858-ac1b-ef2e4858c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"VP\", DoubleType(), True),\n",
    "    StructField(\"FP\", DoubleType(), True),\n",
    "    StructField(\"FN\", DoubleType(), True),\n",
    "    StructField(\"VN\", DoubleType(), True),\n",
    "    StructField(\"precision\", DoubleType(), True),\n",
    "    StructField(\"recall\", DoubleType(), True),\n",
    "    StructField(\"specificity\", DoubleType(), True),\n",
    "    StructField(\"accuracy\", DoubleType(), True),\n",
    "    StructField(\"w_nome\", DoubleType(), True),\n",
    "    StructField(\"p_nome\", DoubleType(), True),\n",
    "    StructField(\"w_nome_mae\", DoubleType(), True),\n",
    "    StructField(\"p_nome_mae\", DoubleType(), True),\n",
    "    StructField(\"w_dt_nasc\", DoubleType(), True),\n",
    "    StructField(\"p_dt_nasc\", DoubleType(), True),\n",
    "    StructField(\"w_sexo\", DoubleType(), True),\n",
    "    StructField(\"p_sexo\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "metrics = spark.createDataFrame([], schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b130871-c830-423e-a482-51ecaf86a0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/02 21:14:17 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 39\n",
      "Número de registros na base de treino: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros na base de treino: 50\n"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    # Criando similaridades entre os pares de atributos\n",
    "    link_df_ = calcula_similaridades(link_df, cfg, row)\n",
    "    # Criando a similaridade total\n",
    "    link_df_ = calcula_similaridade(link_df_, cfg, row)\n",
    "    \n",
    "    # Calculando um ponto de corte usando a ROC\n",
    "    ## transferindo para pandas\n",
    "    df = link_df_.select([\"match_status\", \"total_score\"]).toPandas()\n",
    "\n",
    "    ## calculando taxa de acertos\n",
    "    ### classes (1: link, 0: non-link)\n",
    "    y_true = df[\"match_status\"].values\n",
    "    ### similaridade atribuída as classes\n",
    "    y_score = df[\"total_score\"].values\n",
    "    ### Usando a curva roc \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    # roc_auc = auc(fpr, tpr) # não preciso calcular isso agora\n",
    "    ### usando o youden para encontrar o melhor entre os thresholds\n",
    "    j_scores = tpr - fpr\n",
    "    best_idx = np.argmax(j_scores)\n",
    "    \n",
    "    best_threshold = thresholds[best_idx]\n",
    "    best_tpr = tpr[best_idx]\n",
    "    best_fpr = fpr[best_idx]\n",
    "    # best_threshold\n",
    "\n",
    "    # Criando metricas\n",
    "    link_df_ = link_df_.withColumn(\n",
    "    \"pair_class\",\n",
    "    F.when(\n",
    "        (F.col(\"match_status\") == 1) & (F.col(\"total_score\") >= F.lit(best_threshold)), \"VP\"\n",
    "    ).when(\n",
    "        (F.col(\"match_status\") == 1) & (F.col(\"total_score\") < F.lit(best_threshold)), \"FN\"\n",
    "    ).when(\n",
    "        (F.col(\"match_status\") == 0) & (F.col(\"total_score\") < F.lit(best_threshold)), \"VN\"\n",
    "    ).when(\n",
    "        (F.col(\"match_status\") == 0) & (F.col(\"total_score\") >= F.lit(best_threshold)), \"FP\"\n",
    "    ).otherwise(\"NA\"))\n",
    "\n",
    "    metrics_ = link_df_.agg(\n",
    "    F.sum(F.when(F.col(\"pair_class\") == \"VP\", 1).otherwise(0)).alias(\"VP\"),\n",
    "    F.sum(F.when(F.col(\"pair_class\") == \"FP\", 1).otherwise(0)).alias(\"FP\"),\n",
    "    F.sum(F.when(F.col(\"pair_class\") == \"FN\", 1).otherwise(0)).alias(\"FN\"),\n",
    "    F.sum(F.when(F.col(\"pair_class\") == \"VN\", 1).otherwise(0)).alias(\"VN\"))\n",
    "\n",
    "    metrics_ = metrics_.withColumn(\n",
    "        \"precision\", F.col(\"VP\") / (F.col(\"VP\") + F.col(\"FP\"))\n",
    "    ).withColumn(\n",
    "        \"recall\", F.col(\"VP\") / (F.col(\"VP\") + F.col(\"FN\"))\n",
    "    ).withColumn(\n",
    "        \"specificity\", F.col(\"VN\") / (F.col(\"VN\") + F.col(\"FP\"))\n",
    "    ).withColumn(\n",
    "        \"accuracy\", (F.col(\"VP\") + F.col(\"VN\")) /\n",
    "                    (F.col(\"VP\") + F.col(\"FP\") + F.col(\"FN\") + F.col(\"VN\")))\n",
    "\n",
    "    for key in row.keys():\n",
    "        metrics_ = metrics_.withColumn(key, F.lit(row[key]))\n",
    "        \n",
    "    metrics = metrics.union(metrics_)\n",
    "    # print(row)\n",
    "    print(f\"Número de registros na base de treino: {metrics.count()}\")\n",
    "    # del(df)\n",
    "    # link_df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca455a28-5650-4c32-8ebb-342f73be05bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>VN</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>w_nome</th>\n",
       "      <th>p_nome</th>\n",
       "      <th>w_nome_mae</th>\n",
       "      <th>p_nome_mae</th>\n",
       "      <th>w_dt_nasc</th>\n",
       "      <th>p_dt_nasc</th>\n",
       "      <th>w_sexo</th>\n",
       "      <th>p_sexo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>422.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>0.965675</td>\n",
       "      <td>0.753571</td>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.847</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>435.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>0.970982</td>\n",
       "      <td>0.776786</td>\n",
       "      <td>0.970455</td>\n",
       "      <td>0.862</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.35</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.741</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>431.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0.968539</td>\n",
       "      <td>0.769643</td>\n",
       "      <td>0.968182</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>0.965753</td>\n",
       "      <td>0.755357</td>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.848</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      VP    FP     FN     VN  precision    recall  specificity  accuracy  \\\n",
       "0  422.0  15.0  138.0  425.0   0.965675  0.753571     0.965909     0.847   \n",
       "1  435.0  13.0  125.0  427.0   0.970982  0.776786     0.970455     0.862   \n",
       "2  301.0   0.0  259.0  440.0   1.000000  0.537500     1.000000     0.741   \n",
       "3  431.0  14.0  129.0  426.0   0.968539  0.769643     0.968182     0.857   \n",
       "4  423.0  15.0  137.0  425.0   0.965753  0.755357     0.965909     0.848   \n",
       "\n",
       "   w_nome  p_nome  w_nome_mae  p_nome_mae  w_dt_nasc  p_dt_nasc  w_sexo  \\\n",
       "0    5.15    0.18        0.15        0.64       2.20       0.47    0.45   \n",
       "1    3.85    0.35        5.00        0.79       4.25       0.91    4.35   \n",
       "2    5.15    0.65        0.55        0.30       1.00       0.97    4.40   \n",
       "3    1.70    0.64        3.65        0.76       0.70       0.52    3.85   \n",
       "4    3.95    0.45        2.75        0.34       0.95       0.28    0.85   \n",
       "\n",
       "   p_sexo  \n",
       "0    0.37  \n",
       "1    0.17  \n",
       "2    0.92  \n",
       "3    0.83  \n",
       "4    0.22  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b736c913-0f21-4dd8-82ae-fd63cfb867e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "metrics.write.parquet(\"hdfs://barravento:9000/data/result/train_dataset_final.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "815c015d-3b18-4f55-bb50-eeb6cad4271c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]"
     ]
    }
   ],
   "source": [
    "metrics.coalesce(1).write.csv(\"hdfs://barravento:9000/data/result/train_dataset_final.csv\", header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
